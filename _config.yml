# Site
repository: saraswatdinesh/saraswatdinesh.github.io
favicon: images/favicon.ico

version: 2

# Personal info
name: Dinesh Saraswat
title: Data Engineer / Data Scientist
email: dineshsaraswat@outlook.com

# Social links
#twitter_username: sproogen
github_username:  saraswatdinesh
# dribbble_username:
# facebook_username:
# flickr_username:
#instagram_username: jameswgrant
linkedin_username: dineshrksaraswat
# pinterest_username:
# youtube_username:

# About Section
# about_title: About Me
about_profile_image: images/profile.jpg
about_content: |
  Hi, Iâ€™m Dinesh Saraswat, currently pursuing a Master's in Business Analytics at California State University. With 11 years of professional experience as a Data Professional , I've specialized in the Healthcare, Payment, and Consulting, bringing enthusiasm and expertise to data analysis. 

  My analytical and communication skills enable me to decode intricate data driven business problems, aiding in strategic decision-making. Alongside my academic pursuits, I possess proficiency in : 

  <mark>Python</mark>
  <mark>PySpark</mark>
  <mark>Distributed data processing</mark>
  <mark>ETL</mark>
  <mark>Data Warehouse</mark>
  <mark>Data Science</mark>
  <mark>Data Analysis</mark>
  <mark>Business Analysis</mark>
  <mark>Project Management</mark>
  <mark>R</mark>
  <mark>SQL</mark>
  <mark>Tableau</mark> and
  <mark> AWS </mark>.

content:
  - title: Projects # Title for the section
    layout: list
    content:
      - layout: top-middle
        border: weak
        title: "Real Estate Listing Trend Analysis"
        link: https://github.com/saraswatdinesh/Real_Estate_Listing_Trend_Analysis
        additional_links:
          - title: Real Estate Listing Trend Analysis
            icon: fab fa-github
            url: https://github.com/saraswatdinesh/Real_Estate_Listing_Trend_Analysis
        quote: >
          Real Estate Market Trend Analysis: Identifying Cities with Declining Property Listing Prices.
        description: |
          This is a data analysis project where I acquired the data through web-scrapping and cleaned it with the python-pandas for the exploratory data analysis.
          
          Goal of this project was to identify the current market trends for better investment opportunities in housing, unaffordable housing situtaion and safe haven cities still showing promising trends.
          
          This allowed us to have discussion on the market sentiment backed by data instead of gut feel, which is really important.

          Tech Stack Used - <mark>python</mark> <mark>pandas</mark> <mark>statistics</mark> <mark>Visualization</mark> and <mark>web-scrapping</mark>.
      - layout: top-middle
        title: HealthCare Claims Prediction
        link: https://github.com/saraswatdinesh/HealthCareClaimsPrediction
        additional_links:
          - title: HealthCare Claims Prediction
            icon: fab fa-github
            url: https://github.com/saraswatdinesh/HealthCareClaimsPrediction
        quote: >
          Predicting claims based on Patient's Profile.
        description: |
          A machine learning model that can help predict the claims amoount of patient for the next fiscal year based on the past hitorical claims data as well as the prevailing health conditions.

          We have leveraged the data available for patients last 4 year claims, his/her age, precondition with severity level such as Hyper Tension, High Blood pressure and Diabetes. 

          We were able to leverage the EDA to understand the corelation and importance of certain information with the claims amount and based on that we decided to do the feature engineeing and build a decision treee based LGBMRegresssor model, which was able to predict the claims with the mean absolute error of approx 700.
          Its an ongoing process and we will further do the missing data, model testing and more model changes to further the models performance to make it more fast and lean, with less mean absolute error.
          
          Tech Stack Used - <mark>python</mark> <mark>pandas</mark> <mark>seaborn</mark> <mark>Machine learning</mark> <mark>LGBMRegressor</mark> <mark>Decision Tree</mark> <mark>Hyper Parameter Tunning</mark> 
          
          Feel free to check out the whole project on GitHub to get a feel for how I work [here](https://github.com/saraswatdinesh/HealthCareClaimsPrediction).
      - layout: top-middle
        title: Car Price Prediction - Regression - Kaggle Competition
        link: https://www.kaggle.com/code/dineshsaraswat/car-price-prediction
        additional_links:
          - title: Car Price Prediction - Regression - Kaggle Competition
            icon: fab fa-github
            url: https://www.kaggle.com/code/dineshsaraswat/car-price-prediction
        quote: >
          Predicting Used Car prices
        description: |
          <strong>Ranked 179 on public and 390 on private leaderboard on Kaggle amount 4000 entries.</strong>

          I developed a machine learning model to predict used car prices based on features such as brand, model, engine, mileage, fuel type, color, and accident history. 
          
          This was part of a Kaggle project where I utilized an LLM-generated dataset and tested multiple models, ultimately identifying an ensemble of LGBMRegressor and CatBoost as the best performers. 
          The project involved extensive data preprocessing, cleaning, feature engineering, and model selection, along with hyperparameter tuning using the AUTOGLUON library. 
          
          To further reduce RMSE, I implemented a weighted ensemble method, combining the predictions from both models. This project provided valuable experience in advanced modeling techniques.
          
          Tech Stack Used - <mark>python</mark> <mark>pandas</mark> <mark>seaborn</mark> <mark>Machine learning</mark> <mark>LGBMRegressor</mark> <mark>Decision Tree</mark> <mark>Autogluon</mark>
          
          Feel free to check out the whole project on GitHub to get a feel for how I work [here](https://www.kaggle.com/code/dineshsaraswat/car-price-prediction).

      - layout: top-middle
        title: Mushroom Binary Classification - Kaggle Competition 
        link: https://www.kaggle.com/code/dineshsaraswat/mushroom-prediction
        additional_links:
          - title: Mushroom Binary Classification
            icon: fab fa-github
            url: https://www.kaggle.com/code/dineshsaraswat/mushroom-prediction
        quote: >
          Predicting Poisonous and Edible Mushrooms
        description: |
          <strong>Ranked 544 on private leaderboard on Kaggle amount 2422 entries.</strong>

          I developed a machine learning model to predict if mushroom is poisonous or edible based on the stem root, flower size, fin size. 
          
          This was part of a Kaggle project where I utilized an LLM-generated dataset and tested multiple models, ultimately LGBMClassifier with best hypertunning parameters. 
          This project provided valuable experience in advanced modeling techniques.
          
          Tech Stack Used - <mark>python</mark> <mark>pandas</mark> <mark>seaborn</mark> <mark>Machine learning</mark> <mark>LGBMLGBMClassifier</mark>
          
          Feel free to check out the whole project on GitHub to get a feel for how I work [here](https://www.kaggle.com/code/dineshsaraswat/mushroom-prediction).

  - title: Experience
    layout: list
    content:
      - layout: left
        border: weak
        title: Mastercard
        sub_title: Senior Data Engineer
        caption: September 2019 - Oct 2022
        description: |
          - "Led a **cross-functional team** of 10 through major project releases, demonstrating **strong leadership** by fostering collaboration, accountability, and effective communication, resulting in 100% on-time project deliveries."

          - "Proactively diagnosed and resolved **critical data quality issues**, leveraging **technical expertise** to process 60 million daily transactional records over 3 years within 1 month. Automated data processing with **innovative self-trigger mechanisms**, integrated **rigorous data quality checks**, and established **real-time notifications** to keep stakeholders informed."

          - "Successfully upgraded a **monolithic data pipeline** to a **distributed system** using **Spark**, **Minio**, and **Apache NiFi**, demonstrating **technical innovation** that reduced data processing time from 12 hours to just 2 hours. Optimized system performance through **data flow automation** and improved operational efficiency."

          - "Redesigned the global debit data pipeline, separating it into two pipelines for India and global operations to ensure compliance with local data storage laws. Led **stakeholder discussions**, performed **in-depth system analysis**, resolved **complex data integrity challenges**, and provided **user education** to ensure smooth adoption of the new pipelines."

          - "Contributed to the **migration** of a mainframe-based data processing pipeline to a **Spark-based distributed system**, utilizing **technical expertise** to support the transformation of the organization's data infrastructure before relocating to the US."
          
          - "Tech Stack" : 
            
            **Data Processing**: <mark>Spark</mark>, <mark>Apache NiFi</mark>, <mark>Minio</mark>, <mark>Syncsort</mark>, <mark>pig</mark>
          
            **Database**: <mark>SQL</mark>, <mark>Stored Procedures</mark>, <mark>Netezza</mark>, <mark>HIVE</mark>, <mark>Oracle</mark>
          
            **Automation**: <mark>Batch scheduler</mark>, <mark>cron</mark>
          
            **Cloud Technologies**: <mark>AWS</mark>
          
            **Data Quality**: <mark>Data Quality Checks</mark>, <mark>Real-Time Notifications</mark>
          
            **Data Pipeline**: <mark>Distributed Data Pipelines</mark>, <mark>Monolithic to Distributed Migration</mark>
          
            **Data Flow Optimization**: <mark>Spark-based Data Flow</mark>, <mark>System Optimization</mark>
          
            **Collaboration Tools**: <mark>Stakeholder Discussions</mark>, <mark>User Training</mark>

      - layout: left
        border: weak
        title: Exusia
        sub_title: Senior Consultant
        caption: February 2017 - September 2019
        description: |
          - "Implemented a **stored procedure-driven solution** to efficiently retrieve critical data from the claims database, reducing SQL execution time from **45 minutes to 30 seconds**. Demonstrated **strong technical proficiency** in SQL optimization and **problem-solving skills** to streamline processes."

          - "Designed and documented comprehensive **test cases** after **collaborative discussions** with onshore stakeholders for a healthcare client, ensuring accurate alignment with business requirements and improving testing efficiency."
          
          - "Spearheaded the development of an **SQL training module** for new graduate students, creating **structured coursework** and conducting multiple **hands-on training sessions**, fostering **technical skill development** for entry-level analysts."
          
          - "Actively contributed to **recruitment initiatives** by participating in the hiring process for both **fresh and lateral talent**, showcasing strong **interpersonal skills** and commitment to team growth.

          - "Tech Stack" : 
          
            **Collaboration Tools**: <mark>Stakeholder Discussions</mark>
          
            **Database**: <mark>SQL</mark>, <mark>Stored Procedures</mark>, <mark>Netezza</mark>

      - layout: left
        border: weak
        title: DataMetica
        sub_title: Senior Consultant
        caption: July 2016 - January 2017
        description: |
          - "Proactively identified **critical data quality discrepancies** between Oracle transaction fact data and HIVE fact data, uncovering a significant 1% variance, equating to a **$6M difference in sales**. Performed an **in-depth analysis** of data ingestion and generation rules, and **successfully implemented** corrective measures, ensuring **accurate and reliable reporting**."

          - "Conducted an **in-depth and comprehensive analysis** on the influence of **local weather conditions** and **local events** on the sales performance of specific product categories. Performed **correlation analysis**, **market basket analysis**, and **exploratory data analysis (EDA)** on sales data at the zone level, providing **actionable insights** to optimize marketingâ€‹."

          - "Tech Stack" : 
          
            **Analytics**: <mark>Coorelation</mark> <mark>Pandas</mark> <mark>Excel</mark><mark>matplotlib</mark>
          
            **Database**: <mark>SQL</mark>, <mark>HIVE</mark>, <mark>AWS</mark>
      - layout: left
        border: weak
        title: ZS Associates
        sub_title: Senior Technology Analyst
        link: www.zs.com
        caption: June 2015 - July 2016
        description: |
          - "Successfully **led the initiative** to develop a **scalable data mart solution** for Gilead's clinical trial studies, managing a team of 4 developers. Collaborated closely with stakeholders during **requirement discussions**, and **designed a robust technical architecture** to support **high-volume data processing** and **configurable data quality checks**. Demonstrated **strong leadership** by overseeing the entire solution-building process, ensuring the system's adaptability and efficiency in handling complex data workflows."

          - "Successfully **led a project** to develop a **standardized data profiling engine** that enabled the detection of **data quality trends** in clients' raw data. This initiative significantly reduced costs by minimizing manual efforts required for each implementation, demonstrating **proactive leadership** and **technical innovation** in automating data quality processes."

          - "Mentored Technology Analysts on **career development paths** and **best practices** at ZS, ensuring alignment with individual career goals while fostering **professional growth** and encouraging **skill enhancement** to achieve long-term success.
         
          -"Tech Stack :"
          
            **Collaboration Tools**: <mark>Stakeholder Discussions</mark> <mark>Project Planning</mark> <mark>Team Management</mark>
          
            **ETL**: <mark>Informatica</mark>
          
            **Database**: <mark>SQL</mark> <mark>Stored Procedures</mark> <mark>Oracle</mark>
          
            **Automation**: <mark>Batch scheduler</mark>
      - layout: left
        border: weak
        title: ZS Associates
        sub_title: Technology Analyst
        link: www.zs.com
        caption: June 2013 - May 2015
        description: |
          - "Implemented an **innovative sales forecasting**, **sales alignment**, and **quota reporting solution** for pharmaceutical clients, including Alere and Galderma. This transformative solution enabled enhanced sales management and precise quota alignment based on **real-time**, updated reports, significantly reducing quota assignment and sales compensation determination time from weeks to just a couple of days."
          
          - "Designed and implemented **robust ETL pipelines** in Informatica and SAP BODS, efficiently processing sales, quota, forecasting, and territory alignment data for employees to generate comprehensive sales reports for clients such as Johnson & Johnson."
          
          - "Designed, developed, and implemented **highly efficient ETL code** in DataStage, processing airline ARC data to generate **insightful OD pair reports** for merger and acquisition analysis, contributing to strategic decision-making."

          - "Tech Stack: "
            **Collaboration Tools**: <mark>Stakeholder Discussions</mark> <mark>Project Planning</mark> <mark>Team Management</mark>
          
            **ETL**: <mark>Informatica</mark> <mark>DataStage</mark>  <mark>SAP BODS</mark>
          
            **Database**: <mark>SQL</mark> <mark>Teradata</mark> <mark>Oracle</mark>
            
            **Reporting**: <mark>Microstrategy</mark>
            
            **Automation**: <mark>Batch scheduler</mark>
      - layout: left
        title: Wipro technologies
        sub_title: Project Engineer
        link: www.gwsmedia.com
        caption: October 2011 - May 2013
        description: |
          - "Designed, developed, and implemented **efficient ETL code** in IBM DataStage for processing **Workforce Management data** as part of the **Enterprise Data Warehouse**, ensuring seamless data integration and contributing to enhanced operational efficiency."
          
          - Tech Stack:
            **ETL**: <mark>DataStage</mark> 
            **Database**: <mark>Teradata</mark> 

  - title: Education
    layout: list
    content:
      - title: California State University East Bay
        sub_title: MS Business Analytics
        caption: 2023 - 2024
        description: |

          - "**Relevant Courses are**:  Data Mining, Big Data, Data Analytics, Advance Analytics, Statistics, DataWarehouse, Regression Analysis, Time Series Analytics, Hypothesis Testing, Data Visualization and Project Management"
      - title: RGTU, Bhopal , India
        sub_title: BE, Computer Science and Engineering
        caption: 2007 - 2011
        description: |

          - "**Relevant Courses are**:  Java Programming, Data Structure, Mathematics , Physics, Software engineering principles, Operating Systems, Network programming, Linear Algebra"


  - title: When I'm Not Programming
    layout: text
    content: | # this will include new lines to allow paragraphs
      When I'm not sat at my desk I am very active and spend most of my time outdoors. I do a lot a sports such as
      volleyball, pickleball and cricket.

# Footer
footer_show_references: false

# Build settings
remote_theme: sproogen/resume-theme

# sass:
#   style: compressed
